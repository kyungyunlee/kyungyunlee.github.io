<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://kyungyunlee.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kyungyunlee.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-11-01T11:34:08+00:00</updated><id>https://kyungyunlee.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">DSP#3 Fourier tranforms summary</title><link href="https://kyungyunlee.github.io/study/2022/03/27/dsp3.html" rel="alternate" type="text/html" title="DSP#3 Fourier tranforms summary"/><published>2022-03-27T00:00:00+00:00</published><updated>2022-03-27T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2022/03/27/dsp3</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2022/03/27/dsp3.html"><![CDATA[<p>Summary so far.</p> <table> <thead> <tr> <th> </th> <th>Continuous-time</th> <th>Discrete-time</th> </tr> </thead> <tbody> <tr> <td>Periodic</td> <td>Fourier series</td> <td>Discrete fourier transform (DFT)</td> </tr> <tr> <td>Aperiodic</td> <td>Fourier transform</td> <td>Discrete-time Fourier transform (DTFT)</td> </tr> <tr> <td>Aperiodic (general)</td> <td>Laplace transform</td> <td>Z-transform</td> </tr> </tbody> </table> <p>##</p> <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0njuewycaj20k00f040c.jpg" alt="FT"/></p> <h3 id="fourier-series">Fourier series</h3> <p>Synthesis</p> \[x(t) = \sum_{k=-\infty}^{\infty}a_k e^{jk\omega_0t}\] <p>Analysis</p> \[a_k = \frac{1}{T} \int_0^T x(t)e^{-jk\omega_0t}dt\] <h3 id="fourier-transform">Fourier transform</h3> <p>Synthesis</p> \[x(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} X(\omega)e^{j\omega t}d\omega\] <p>Analysis</p> \[X(\omega) = \int_{-\infty}^{\infty} x(t)e^{-j\omega_0t}dt\] <h3 id="laplace-transform">Laplace transform</h3> \[X(s) = \int_{-\infty}^{\infty}x(t)e^{-st}dt\] <p>Equals to fourier transform when \(s=j\omega_0\).</p> <h3 id="dtft">DTFT</h3> <p>Synthesis</p> \[x[n] = \frac{1}{2\pi} \int_{-\pi}^{\pi} X(\omega)e^{j\omega n}d\omega\] <p>Analysis</p> \[X(\omega) = \sum_{n=-\infty}^{\infty}x[n]e^{-j\omega n}\] <h3 id="z-transform">z-transform</h3> \[X(z) = \sum_{n=-\infty}^{\infty} x[n]z^{-n}\] <p>Equals to DTFT when \(z=e^{j\omega}\).</p> <h3 id="dft">DFT</h3> <p>Synthesis</p> \[x[n] = \frac{1}{N} \sum_{n=0}^{N-1}X[k]e^{jk \frac{2\pi}{N}n}\] <p>Analysis</p> \[X[k] = \sum_{n=0}^{N-1} x[n]e^{-jk\frac{2\pi}{N}n}\]]]></content><author><name></name></author><category term="study"/><category term="DSP"/><summary type="html"><![CDATA[DSP study]]></summary></entry><entry><title type="html">DSP#2</title><link href="https://kyungyunlee.github.io/study/2022/03/26/dsp2.html" rel="alternate" type="text/html" title="DSP#2"/><published>2022-03-26T00:00:00+00:00</published><updated>2022-03-26T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2022/03/26/dsp2</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2022/03/26/dsp2.html"><![CDATA[<h2 id="0-key-ideas">0. Key ideas</h2> <p>DSP #1 was about performing fourier analysis for the continous time signal. Now, time for discrete time signals.</p> <h3 id="1-dtft">1. DTFT</h3> <p>DTFT evaluates discrete-time aperiodic signals.</p> <p>Compared to CTFT :</p> <ul> <li> <p>CTFT is for continuous-time aperiodic signal. It has a frequency range \((-\infty, \infty)\). Any frequency can exist.</p> \[X(\omega) = \int_{-\infty}^{\infty} x(t)e^{-j\omega_0t}dt\] </li> <li> <p>DTFT has frequency range \(2\pi\). Thus DTFT is periodic, which means that there can only be a limited value of frequency that can exist. However, frequency values are still continous within the \(2\pi\) range.</p> </li> </ul> \[X(\omega) = \sum_{n=-\infty}^{\infty}x[n]e^{-j\omega n}\] \[x[n] = \frac{1}{2\pi} \int_{-\pi}^{\pi} X(\omega)e^{j\omega n}d\omega\] <h3 id="2-z-transform">2. z-transform</h3> <p>z-transform is a more general version of DTFT. DTFT don’t always exist/converge, since it cannot be computed for signals that are not stable. However, z-transform can.</p> <p>Let $z^n$ be an eigenfunction of a discrete-time LTI system. (\(e^{jwn}\) is that of a continuous-time LTI system)</p> \[x[n] = z^n\] \[y[n] = \sum_{k=-\infty}^{\infty}h[k]x[n-k] = H(z)z^n\] <p>$H(z)$ is called a transfer function and is a complex number.</p> <p>Z-transform is :</p> \[X(z) = \sum_{n=-\infty}^{\infty} x[n]z^{-n}\] <p>This equals to DTFT when \(z=e^{j\omega}\), meaning that DTFT is when z value is on a unit circle in the z-plane. This is also the reason why DTFT is \(2\pi\) periodic.</p> <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0nl1iziapj20hf0e1mxh.jpg" alt="DFT-49 2"/></p> <p>The benefit of z-transform is that it can be used to evaluate systems that are not stable (ex. feedback loop).</p> <h4 id="properties-of-z-transform">Properties of z-transform</h4> \[x[k] \Leftrightarrow X(z)\] <p>Time reversal</p> \[x[-k] \Leftrightarrow X(\frac{1}{z})\] <p>Time shift</p> \[x[k-k_0] \Leftrightarrow z^{-k_0}X(z)\] <p>Exponential sequence</p> \[\alpha^k x[k] \Leftrightarrow X(\frac{z}{\alpha})\] <p>z-domain differentiation</p> \[kx[k] \Leftrightarrow -z\frac{d}{dz}X(z)\] <h4 id="region-of-convergence-roc">Region of convergence (ROC)</h4> <p>If \(z=re^{j\omega}\), then z-tranform looks like DTFT applied to \(x[n]r^{-n}\).</p> \[X(z) = X(re^{j\omega}) = \sum_{n=-\infty}^{\infty} (x[n]r^{-n})e^{-jwn} = DTFT(x[n]r^{-n})\] <p>Thus, we can say that z-tranform converges if</p> \[\sum_{n=-\infty}^{\infty} \lvert x[n]r^{-n} \rvert &lt; \infty\] <p>If ROC includes the unit circle, we say the system is stable.</p> <h4 id="poles-and-zeros">Poles and zeros</h4> \[X(z) = \frac{N(z)}{D(z)}\] <p>\(N(z) = 0\) are zeros, \(D(z) = \infty\) are poles.</p> <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0oapmm89wj210w0fe3zs.jpg" alt="Screen Shot 2022-03-27 at 12.48.18 PM"/></p> <h3 id="3-dft">3. DFT</h3> <p>More appropriate name is discrete fourier series. DFT analyzes finite and periodic digital input signal x. The resulting frequency domain is discrete (unlike DTFT).</p> <p>Compare DTFT with DFT.</p> \[X(\omega) = \sum_{n=-\infty}^{\infty}x[n]e^{-j\omega n}\] \[X[k] = \sum_{n=0}^{N-1} x[n]e^{-jk\frac{2\pi}{N}n}\] <p>These two are almost equivalent, when \(\omega = \frac{2\pi k}{N}\). Also, unlike DTFT, input x[n] is finite/periodic.</p> <p>In other words, we can interprete DFT as DTFT sampled in the frequency domain at \(\omega = \frac{2\pi k}{N}\) interval.</p> <p>DFT can be computed via matrix multiplication:</p> <p><img src="https://tva1.sinaimg.cn/large/e6c9d24egy1h0nkdgkcdzj212c0j9aby.jpg" alt="DFT-49"/></p> <p>A faster algorithm of DFT is FFT.</p>]]></content><author><name></name></author><category term="study"/><category term="DSP"/><summary type="html"><![CDATA[DSP study]]></summary></entry><entry><title type="html">DSP#1</title><link href="https://kyungyunlee.github.io/study/2022/03/06/dsp1.html" rel="alternate" type="text/html" title="DSP#1"/><published>2022-03-06T00:00:00+00:00</published><updated>2022-03-06T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2022/03/06/dsp1</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2022/03/06/dsp1.html"><![CDATA[<p>Notes from lectures 1 - 6</p> <h3 id="0-key-ideas">0. Key ideas</h3> <ul> <li>The goal is to represent any continous signals as a sum of sinusoids (aka. complex exponentials).</li> <li>Fourier series is for periodic, continuous signal, while fourier transform is for non-periodic, continuous signal.</li> </ul> <p><img src="/posts/501967_1_En_22_Figa_HTML.png" alt="501967_1_En_22_Figa_HTML"/></p> <p>### 1. Fourier series</p> <p>All periodic, continuous signals can be represented as a sum of sinusoids.</p> \[x(t) = \sum_{k=-\infty}^{\infty}a_k e^{jk\omega_0t}\] \[a_k = \frac{1}{T} \int_0^T x(t)e^{-jk\omega_0t}dt\] <p>\(a_k\) is a coefficient, which represents the magnitude of the \(k\)-th sinusoid with frequency \(k\omega_0\). These coefficients are complex values.</p> <h4 id="11-what-if-input-signal-x-is-real">1.1 What if input signal \(x\) is real?</h4> <p>Then, \(a_k\) is symmetric. \(a_k = a_{-k}*\).</p> <p>If the signal is real, we can represent it only with cosines, since cosines are the real part of the complex exponentials.</p> \[x(t) = a_0 + \sum 2A_k cos(\theta_k + k\omega_0t)\] <p>Where \(A_k\) is the amplitude and \(\theta_k\) is the phase shift value of cosines.</p> <h4 id="12-what-is-the-fourier-series-of-a-pulse-train">1.2 What is the fourier series of a pulse train?</h4> <p>\(a_k\)s are sinc functions.</p> <h4 id="13-properties-of-fs">1.3 Properties of FS</h4> <ul> <li>Linearity</li> <li>Time shifting <ul> <li>The \(a_k\) of the time shifted signal is a phase shifted version of the \(a_k\) of the original signal.</li> <li>No magnitude changes.</li> </ul> </li> <li>Differentiation</li> <li>Parseval’s</li> <li>Convolution <ul> <li>Convolution in one domain is a multiplication in the other domain</li> </ul> </li> </ul> <h4 id="14-gibbs-phenomenon">1.4 Gibbs phenomenon</h4> <h3 id="2-fourier-transform">2. Fourier transform</h3> <p>Not all signals are periodic. How can we represent non-periodic, continous signal as a sum of sinusoids?</p> <p>We can manipulate the non-periodic signal as having an infinitely long period and use FS to derive FT. As a result,</p> \[x(t) = \frac{1}{2\pi}\int_{-\infty}^{\infty} X(\omega)e^{j\omega t}d\omega\] <p>where,</p> \[X(\omega) = \int_{-\infty}^{\infty} x(t)e^{-j\omega_0t}dt\] <p>These are called synthesis and analysis equations, respectively.</p> <h4 id="22-properties-of-ft">2.2 Properties of FT</h4> <ul> <li>Linearity</li> <li>Time shift</li> <li>Symmetry <ul> <li>Even(\(x(t)\)) &lt;-&gt; Re(\(X(\omega)\))</li> <li>Odd(\(x(t)\)) &lt;-&gt; \(j\)Im(\(X(\omega)\))</li> </ul> </li> <li>Differentiation/integration</li> </ul> \[x'(t) \Leftrightarrow j\omega X(\omega)\] \[\int_{-\infty}^t x(\tau)d\tau \Leftrightarrow \frac{1}{j\omega}X(\omega) + \pi X(0)\delta(\omega)\int_{-\infty}^t x(\tau)d\tau \Leftrightarrow \frac{1}{j\omega}X(\omega) + \pi X(0)\delta(\omega)\] <ul> <li> <p>Time scaling \(x(at) \Leftrightarrow \frac{1}{\vert a \vert} X(\frac{\omega}{a})\)</p> </li> <li> <p>Duality</p> <ul> <li>pulse &lt;-&gt; sinc function</li> <li>delta &lt;-&gt; constant</li> </ul> </li> <li> <p>Parseval</p> </li> </ul> \[\int_{-\infty}^{\infty} \lvert{x(t)}\rvert^2dt = \frac{1}{2\pi}\int_{-\infty}^{\infty} \lvert{X(\omega)}\rvert^2 d\omega\] <ul> <li>Convolution</li> </ul> \[y(t) = x(t) * h(t)\] \[Y(\omega) = X(\omega)H(\omega)\] <h3 id="3-frequency-response">3. Frequency response</h3> <p>Frequency response (H(w)) : Fourier transform of the impulse response. Aka. filter.</p> <p>⇒ Information about how each frequency will change after going through the LTI system</p> <p>Given x(t) and H(w), we can calculate the output signal y(t)</p> <ol> <li> <p>Compute X(w) by FT</p> </li> <li> <p>Compute Y(w) = H(w)X(w)</p> </li> <li> <p>Compute y(t) by inverse FT</p> </li> </ol> <h3 id="appendix">Appendix</h3> <h4 id="derive-a_k-for-fs">Derive \(a_k\) for FS</h4> <p><img src="/posts/Engineering Math-28.jpg" alt="Engineering Math-28"/></p> <p><img src="/posts/Engineering Math-29.jpg" alt="Engineering Math-29"/></p> <h4 id="fourier-series-of-a-pulse-train">Fourier series of a pulse train</h4> <p><img src="/posts/Engineering Math-30.jpg" alt="Engineering Math-30"/></p> <h4 id="ft-as-fs-where-period-goes-to-infinity">FT as FS where period goes to infinity</h4> <p><img src="/posts/Engineering Math-31.jpg" alt="Engineering Math-31"/></p> <p><img src="/posts/Engineering Math-32.jpg" alt="Engineering Math-32"/></p> <h4 id="deriving-ft-for-various-functions">Deriving FT for various functions</h4> <p><img src="/posts/Engineering Math-33.jpg" alt="Engineering Math-33"/></p> <p><img src="/posts/Engineering Math-34.jpg" alt="Engineering Math-34"/></p> <p><img src="/posts/Engineering Math-35.jpg" alt="Engineering Math-35"/></p> <p><img src="/posts/media_c7a_c7afa2a9-47ad-4363-a0c8-49f6b107d1ff_phpZzh3jE.png" alt="Table of fourier transforms"/></p> <h3 id="references">References</h3> <ul> <li><a href="https://www.youtube.com/playlist?list=PLuh62Q4Sv7BUSzx5Jr8Wrxxn-U10qG1et">DSP lectures</a> by Rich Radke</li> <li><a href="https://www.youtube.com/watch?v=r6sGWTCMz2k">Fourier series</a> by 3Blue1Brown</li> </ul>]]></content><author><name></name></author><category term="study"/><category term="DSP"/><summary type="html"><![CDATA[DSP study]]></summary></entry><entry><title type="html">K-means and GMM</title><link href="https://kyungyunlee.github.io/study/2021/11/16/kmeans_gmm.html" rel="alternate" type="text/html" title="K-means and GMM"/><published>2021-11-16T00:00:00+00:00</published><updated>2021-11-16T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2021/11/16/kmeans_gmm</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2021/11/16/kmeans_gmm.html"><![CDATA[<h2 id="unsupervised-learning">Unsupervised learning</h2> <p>라벨이 없는 데이터들이 있을때, 그 데이터들을 보고 유의미한 정보를 찾는 것이다.</p> <p>Unsupervised learning : clustering = Supervised learning : classification</p> <h2 id="k-means">K-means</h2> <p>주어진 데이터를 k개의 클러스터로 묶는 것이 목표이다.</p> <p>각 클러스터는 cluster centroid가 기준점이 된다. 그냥 vector space에 한 점이다.</p> <p>K-means의 목표는 이 cluster centroid값을 구하고 모든 데이터 포인트를 하나의 클러스터로 라벨링을 해주는 것이다.</p> <p>간단히 이 알고리즘을 설명하자면</p> <ol> <li>일단 데이터에 대한 아무런 사전 정보가 없으므로 cluster centroid들을 랜덤하게 정한다</li> <li>각 데이터 포인트를 그것과 가장 가까운 cluster centroid로 분류해준다</li> <li>각 클러스터마다 자기한테 분류된 데이터 포인트들의 mean값을 구하고 자신의 centroid값을 그걸로 업데이트 해준다.</li> <li>Converge될때까지 2,3번을 반복한다</li> </ol> <p><img src="/Users/kylee/dev/kyungyunlee.github.io/content/posts/K-means an 42af3/스크린샷_2021-11-16_오전_12.21.52.png" alt="스크린샷 2021-11-16 오전 12.21.52.png"/></p> <p>한계점</p> <ul> <li>hard clustering방법이다 <ul> <li>데이터 x가 클러스터 A에 속했다는 것에 대해 1, 0의 바이너리 대답만 줄 수 있다</li> <li>probability, uncertainty에 대한 정보가 없다 → 데이터 x가 클러스터 A에 속한다는 것을 몇프로 확신할 수 있는가? 라는 질문에 답할 수 없다.</li> </ul> </li> <li>단순히 눈에 보이는 동그란 클러스터들이 아닌 우리가 쉽게 정의할 수 없는 모양의 클러스터이면 어떻할건가</li> </ul> <h2 id="gaussian-mixture-model">Gaussian mixture model</h2> <h3 id="목표">목표</h3> <p>라벨이 없는 데이터들이 있는데, 이 데이터들이 어떤 분포들을 가지고 있는지 학습하는 것이다.</p> <p>예를 들면, 아래 그림과 같이 데이터들을 가장 잘 나타낼 수 있는 3개의 gaussian distribution의 파라미터 (mean, covariance, weight) 을 학습하는 것이 목표이다.</p> <p>즉, 2가지의 큰 결정을 내려야한다.</p> <ol> <li>어떤 타입의 distribution을 사용할지</li> <li>Distribution을 대표하는 파라미터들의 값은 어떤걸로 할지</li> </ol> <p>GMM에서는 이름에서 알 수 있듯이 gaussian distribution을 사용한다.</p> <p><img src="/Users/kylee/dev/kyungyunlee.github.io/content/posts/K-means an 42af3/1_lTv7e4Cdlp738X_WFZyZHA.png" alt="1_lTv7e4Cdlp738X_WFZyZHA.png"/></p> <h3 id="기본-정의">기본 정의</h3> <ul> <li>Gaussian mixture 이라는 것은 k gaussian 들의 weighted sum 이다</li> <li>mean, covariance, weight: \(\mu, \Sigma, \pi\) - 각 gaussian은 3가지의 파라미터들로 나타낸다</li> <li>이때 k개의 weight의 합은 1이다 ⇒ 왜냐하면 weight는 확률이기 때문이다. 어떤 데이터가 있을때 그 데이터가 클러스터 j에 포함될 확률을 나타낸다.</li> <li>GMM에서 해야하는 것이 k개의 gaussian의 3개의 파라미터의 최적값을 구하는 것이다.</li> </ul> <p><img src="/Users/kylee/dev/kyungyunlee.github.io/content/posts/K-means an 42af3/스크린샷_2021-11-14_오후_7.50.16.png" alt="스크린샷 2021-11-14 오후 7.50.16.png"/></p> <p>Side note: 모든 데이터는 (이미지이든 텍스트이든 음악이든) 컴퓨터 입장에서 숫자에 불과하다. 머신러닝에서는 기본적으로 이런 데이터들을 n-dimensional vector로 취급한다.</p> <h3 id="overview">Overview</h3> <p>1단계 : 아무것도 모르는 상태이니까 랜덤하게 파라미터들을 정한다</p> <p><img src="/Users/kylee/dev/kyungyunlee.github.io/content/posts/K-means an 42af3/Book_Notes-38_복사본.jpg" alt="Book Notes-38 복사본.jpg"/></p> <p>2단계: MLE를 계산해서 가장 likely한 distribution으로 라벨을 달아준다</p> <p><img src="K-means%20an%2042af3/Book_Notes-38_%E1%84%87%E1%85%A9%E1%86%A8%E1%84%89%E1%85%A1%E1%84%87%E1%85%A9%E1%86%AB1.jpg" alt="Book Notes-38 복사본1.jpg"/></p> <p>3단계: 각 distribution으로 분류된 데이터들의 mean, std로 distribution의 파라미터들을 업데이트 해준다.</p> <p><img src="K-means%20an%2042af3/Book_Notes-38.jpg" alt="Book Notes-38.jpg"/></p> <p>그럼 업데이트 된 새로운 distribution으로 다시 데이터들을 라벨링 해주고 (2단계) 또 파라미터 업뎃해주는 (3단계) 방식을 반복한다.</p> <p>이런식으로 iterative하게 업데이트를 하는 방법을 조금 더 general하게 디자인한 것이 EM algorithm이다.</p> <h1 id="expectation-maximization-in-gmm">Expectation-maximization in GMM</h1> <p>Expectation 단계에서는 likelihood를 계산해주고 (즉 라벨링을 달아주고) maximization 단계에서는 최적의 파라미터들로 업데이트 시켜준다고 보면 된다.</p> <p><strong>먼저 짚고 넘어가야할 개념들</strong></p> <ul> <li>Gaussian density function</li> </ul> <p>주어진 gaussian이 있을때, x 를 observe할 수 있는 확률을 나타내는 함수</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-16_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.02.11.png" alt="스크린샷 2021-11-16 오전 12.02.11.png"/></p> <ul> <li>Log likelihood</li> </ul> <p>GMM이 잘 학습이 되었다라는 기준은 log likelihood이다. GMM에서는 아래의 log likelihood 가 최대가 되도록 하는 것이 목표이다. (MLE)</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-16_%E1%84%8B%E1%85%A9%E1%84%8C%E1%85%A5%E1%86%AB_12.04.59.png" alt="스크린샷 2021-11-16 오전 12.04.59.png"/></p> <ul> <li>Latent variable \(z\)</li> </ul> <p>\(z\) 는 one-hot 벡터이고 \(z_k = 1\) 또는 \(0\) 이다. 데이터 x가 k 클러스터에서 포함된다는 것을 나타낼 때 \(z_k = 1\) 이다.</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-18_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_4.38.36.png" alt="스크린샷 2021-11-18 오후 4.38.36.png"/></p> <ul> <li>p(z)</li> </ul> <p>클러스터 3개중에 하나의 클러스터를 고른다고 할때 그 확률을 나타낸다. 만약 그 클러스터의 weight가 크다면, 그 클러스터가 선택될 확률이 그만큼 크다는 뜻이다.</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-15_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.50.18.png" alt="스크린샷 2021-11-15 오후 11.50.18.png"/></p> <ul> <li> <table> <tbody> <tr> <td>p(x</td> <td>z)</td> </tr> </tbody> </table> </li> </ul> <p>주어진 클러스터에서 x를 observe할 수 있는 likelihood를 나타내는 수식이다. 이건 gaussian function으로 쉽게 나타낼 수 있다.</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-15_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.50.23.png" alt="스크린샷 2021-11-15 오후 11.50.23.png"/></p> <ul> <li>p(x)</li> </ul> <p>앞의 두 식을 이용해서 joint distribution \(p(x,z)\) 을 구할 수 있고 이걸 marginalize 함으로써 \(p(x)\) 를 구할 수 있다. → 데이터 x 를 observe 할 수 있는 확률</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-15_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.55.58.png" alt="스크린샷 2021-11-15 오후 11.55.58.png"/></p> <h3 id="initialization">Initialization</h3> <p>랜덤하게 하거나 좀 더 좋은 방식으로 한다. (K-means의 결과를 사용한다던가)</p> <h3 id="e-step">E-step</h3> <p>\(p(z_j=1|x)\) 를 구하는 과정이다.</p> <p>즉, 데이터 x 가 클러스터 j로 label이 될 확률을 구한다 (posterior distribution). 이건 베이즈 정리를 이용해서 우리가 위에서 구한 \(p(z), p(x|z)\) 로 식을 풀어서 값을 계산한다.</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-15_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.31.11.png" alt="스크린샷 2021-11-15 오후 11.31.11.png"/></p> <h3 id="m-step">M-step</h3> <p>파라미터들을 업데이트하는 과정이다.</p> <p><img src="K-means%20an%2042af3/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2021-11-15_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.31.04.png" alt="스크린샷 2021-11-15 오후 11.31.04.png"/></p> <p>끝 -</p>]]></content><author><name></name></author><category term="study"/><category term="ML"/><summary type="html"><![CDATA[Unsupervised learning]]></summary></entry><entry><title type="html">Probabilty vs Likelihood</title><link href="https://kyungyunlee.github.io/study/2021/11/14/probability_likelikhood.html" rel="alternate" type="text/html" title="Probabilty vs Likelihood"/><published>2021-11-14T00:00:00+00:00</published><updated>2021-11-14T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2021/11/14/probability_likelikhood</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2021/11/14/probability_likelikhood.html"><![CDATA[<p><img src="../../static/posts/1_F_34lcOq-XnaSx0dsHmqQw.png" alt="img"/></p> <h3 id="probability">Probability</h3> <p>What is the probability of observing x given the distribution ?</p> <p>It is the area under the distribution graph.</p> <p>Distribution is fixed and we want to know the probability of observing data x with that distribution.</p> <p>예시)</p> <p>쥐들의 몸무게의 분포를 알고 있는데, 그렇다면 어떤 쥐가 30그람의 몸무게를 가질 확률은 무엇인가?</p> <h3 id="likelihood">Likelihood</h3> <p>Data is fixed and we want to know how likely it is to observe data point under some distribution.</p> <p>We can compare different distributions to find the most likely distribution (aka, a distribution that fits the data the best).</p> <p>예시)</p> <p>30그람의 몸무게를 가진 쥐가 있는데, 어떤 분포가 가장 이 쥐의 몸무게를 잘 나타내주는가?</p> <h3 id="reference">Reference</h3> <ul> <li><a href="https://www.youtube.com/watch?v=pYxNSUDSFH4">StatsQuest</a></li> </ul>]]></content><author><name></name></author><category term="study"/><category term="ML"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">SSH! Be quiet!</title><link href="https://kyungyunlee.github.io/study/2021/02/27/ssh.html" rel="alternate" type="text/html" title="SSH! Be quiet!"/><published>2021-02-27T00:00:00+00:00</published><updated>2021-02-27T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2021/02/27/ssh</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2021/02/27/ssh.html"><![CDATA[<p>I type <code class="language-plaintext highlighter-rouge">ssh -p xxx kyungyunlee@someserver.school.com</code> almost everyday. I also use port forwarding and SCP often. I use it only because google told me to do it that way, when working with a remote machine, but I had no idea what these command meant and what they was doing for me. So, I searched a bit, just enough to serve my curiousity.</p> <h4 id="agenda">Agenda</h4> <ul> <li>What is SSH (secure shell)</li> <li> <p>Major usage</p> </li> <li> <p>History of SSH</p> </li> <li>Why is it secure? How?</li> </ul> <h4 id="what-is-ssh">What is SSH?</h4> <p>SSH is a <strong>cryptographic network protocol</strong> that helps users to securely connect to a machine over an unsecure network.</p> <p>It was developed to be a replacement of other protocols and programs like Telnet, rlogin, FTP and rsh. I am guessing the major drive and the success of SSH is with the rise of internet. Nowadays, major servers (Unix, Linux, Mac) provide SSH by default.</p> <p>SSH is a client-server model: if you are trying to login to a remote machine at work, your local computer is the client and that remote machine is the server/host. It ensures security through authentication and data encryption process.</p> <h4 id="what-are-some-major-usages-of-ssh">What are some major usages of SSH?</h4> <ul> <li> <p>Operating and managing a remote server</p> </li> <li> <p>Tunneling</p> </li> <li> <p>Port forwarding</p> </li> <li> <p>X11 connections</p> </li> </ul> <h4 id="history-of-ssh">History of SSH</h4> <p>Tatu Ylonen from Helsink University of Technology created SSH back in 1995, motivated by some password-sniffing attack that happened at his university. The number of users grew quickly, reaching 2 million by year 2000. SSH we know now is the version 2.x, SSH-2.</p> <p>There is also an OpenSSH, which is a free software version of SSH.</p> <h4 id="what-is-secure">What is secure?</h4> <p>When sending data over a network, SSH encrypts them so that no one else can watch what you are sending. Telnet, for instance, sent data in plain text, so it would be extremely easy to packet sniffer and steal whatever was in your data.</p> <p>When using Telnet, the evil man-in-the-middle can steal your info.</p> <p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnfu8yvyfdj311q0indmd.jpg" alt="Random-8 2 copy" style="zoom: 50%;"/></p> <p>When using SSH, the evil monster won’t know how to read the info.</p> <p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnfu8n4669j310q0gtjto.jpg" alt="Random-8 2" style="zoom:50%;"/></p> <p>Data is segmented and wrapped into packets before sending over the network. Diagram below shows the original and encrypted packet. Packet length is the literal size of the packet in bytes, padding amount is the size of padding, payload is the actual data, padding is random bytes that are added to make it harder to locate data (just in case) and message authentication code tells you if the data is still valid or if it has been ruined.</p> <p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gneysw5k05j30jg0e8jsq.jpg" alt="Random-14" style="zoom:50%;"/></p> <h4 id="so-how-does-all-the-encryption-work">So how does all the encryption work?</h4> <p>To start a SSH session, client initiates the TCP connection to the server. SSH server is listening to any requests on port 22 (default). There are 2 things that needs to be done in order to create a valid SSH session. First, the client and the server needs to create a secret channel that will not be eavesdropped by others. Next, the server needs to authenticate the user’s access to its resources.</p> <p><strong>1. Opening a secret channel</strong></p> <p>To send data safely, we need a secret channel that only the client and the server can use with an identical symmetric key for data encryption. But how can the client and the server share a secret key in the first place? Obviously, naively sending the secret key over a network is not safe. Therefore, a really smart key exchange algorithm is used to not actually send key to each other, but make one together. This algorithm is called <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange">Diffie-Hellman key exchange</a> algorithm. Below is an analogy with color mixing. In reality, <a href="https://en.wikipedia.org/wiki/Multiplicative_group_of_integers_modulo_n">multiplicative group of integers modulo n</a> is used.</p> <p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnfu88sw5yj30u00wr7bw.jpg" alt="Random-19 2" style="zoom:60%;"/></p> <p>As long as the client and the server (Kitty and Pingoo) keep their private keys safely, it is almost impossible for the Bad guy to make the secret key. The highlight of this algorithm is that it is very difficult to “unmix” the already mixed colors.</p> <p><strong>2. Authenticate the client</strong></p> <p>It is not enough to just encrypt the data. What if the client is some imposter? The server must check if the client is trustable before allowing the client to do anything. It can be done by simply asking the client for a password or even a more advanced/better option is to use SSH key-pairs (asymmetric encryption).</p> <p>Both client and the server has a public and a private key-pair. In order to use this type of authentication method, the client should have sent its public key to the server. When times comes and the client tries to connect, the host will identify the client and use its specific public key to encrypt a secret message and send it to the client as a quiz. Since the client can decrypt the message with its private key, the server will know that the client is verified. A common algorithm is RSA.</p> <p><img src="https://tva1.sinaimg.cn/large/008eGmZEgy1gnf7zzi2hpj30k80cz406.jpg" alt="Generating_an_SSH_key_with_ssh-keygen" style="zoom:80%;"/></p> <p>(Img taken from ssh.com website)</p> <h4 id="references">References</h4> <ul> <li> <p>https://levelup.gitconnected.com/what-is-ssh-103f89e3e4b8</p> </li> <li>https://www.comparitech.com/blog/information-security/ssh-encryption</li> <li>https://www.ssh.com/ssh/protocol/https://www.youtube.com/watch?v=ORcvSkgdA58</li> <li>https://www.freecodecamp.org/news/a-top-down-introduction-to-ssh-965f4fadd32e/</li> <li>https://www.digitalocean.com/community/tutorials/understanding-the-ssh-encryption-and-connection-process</li> </ul>]]></content><author><name></name></author><category term="study"/><category term="CS"/><summary type="html"><![CDATA[I type ssh -p xxx kyungyunlee@someserver.school.com almost everyday. I also use port forwarding and SCP often. I use it only because google told me to do it that way, when working with a remote machine, but I had no idea what these command meant and what they was doing for me. So, I searched a bit, just enough to serve my curiousity.]]></summary></entry><entry><title type="html">Clustered vs. non-clustered indexes</title><link href="https://kyungyunlee.github.io/study/2021/01/06/clustered_indexes.html" rel="alternate" type="text/html" title="Clustered vs. non-clustered indexes"/><published>2021-01-06T00:00:00+00:00</published><updated>2021-01-06T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2021/01/06/clustered_indexes</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2021/01/06/clustered_indexes.html"><![CDATA[<p>Indexes in database are used to increase the query performance from the table.</p> <p>Without indexes, when you want to find a specific entry in a large table, you would have to scan through the entire table from beginning to end until you find what you want (Linear searching time).</p> <p>There are two major types of indexes in SQL server: Clustered and non-clustered indexes.</p> <h4 id="analogy">Analogy</h4> <p><strong>Clustered index</strong> - alphabetical sorting of last name and first name in a telephone book.</p> <p><strong>Non-clustered index</strong> - index of chapters at the beginning of a textbook, index of terms at the end of the textbook.</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gmdset2pnfj30gq05tgm6.jpg" alt="main-qimg-a578a13aeca2112760f11b2084f00065"/></p> <p>This diagram helped me understand what “clustered” meant in database. “Clustered” refers to whether the actual rows in the table are close together in the physical table or not. In case of non-clustered index, index pointers are all over the table, while for clustered index, pointers are in order (there can be exceptions once you start inserting lots of rows in the table; will need to perform re-sorting).</p> <h4 id="clustered-index">Clustered index</h4> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gmds9rdtnqj31750u041l.jpg" alt="Data Engineering-4 2" style="zoom: 33%;"/></p> <p>Clustered index is the same as the ordering of the physical table. Therefore, there can be <strong>only one</strong> clustered index per table. Also, since it corresponds directly to the physical table, retrieval is faster than non-clustered table.</p> <p><strong>Pros</strong></p> <ul> <li>Direct / single access to the table</li> <li>Good for sequential retrieval</li> <li>Minimize page transfer and maximize cache hit</li> </ul> <p><strong>Cons</strong></p> <ul> <li>Modification (insertion, updates, deletes) require extra work, such as re-ordering of the tables so that entries are in order.</li> </ul> <h4 id="non-clustered-index">Non-clustered index</h4> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gmds9fycxwj31it0u0aer.jpg" alt="Data Engineering-5" style="zoom:33%;"/></p> <p>Non-clustered index does not correspond to actual orderings in the physical table. It has pointers to the actual entry in the table and is stored in a separately from the table.</p> <p><strong>Pros</strong></p> <ul> <li>Can have multiple non-clustered indexes</li> <li>Insertion into the physical table does not affect performance</li> </ul> <p><strong>Cons</strong></p> <ul> <li>Lookup is costly (No locality, cache misses)</li> <li>Slower data access compared to clustered index</li> <li>Need extra space to store the index</li> </ul> <h4 id="references">References</h4> <ul> <li> <p>https://www.youtube.com/watch?v=HauoKagBM_c&amp;list=PLzzVuDSjP25QCp7S4_8b-rX9vytv6OqsZ&amp;index=5</p> </li> <li> <p>https://www.guru99.com/clustered-vs-non-clustered-index.html</p> </li> </ul>]]></content><author><name></name></author><category term="study"/><category term="CS"/><summary type="html"><![CDATA[Indexes in database are used to increase the query performance from the table. Without indexes, when you want to find a specific entry in a large table, you would have to scan through the entire table from beginning to end until you find what you want (Linear searching time). There are two major types of indexes in SQL server: Clustered and non-clustered indexes. Analogy Clustered index - alphabetical sorting of last name and first name in a telephone book. Non-clustered index - index of chapters at the beginning of a textbook, index of terms at the end of the textbook. This diagram helped me understand what “clustered” meant in database. “Clustered” refers to whether the actual rows in the table are close together in the physical table or not. In case of non-clustered index, index pointers are all over the table, while for clustered index, pointers are in order (there can be exceptions once you start inserting lots of rows in the table; will need to perform re-sorting). Clustered index Clustered index is the same as the ordering of the physical table. Therefore, there can be only one clustered index per table. Also, since it corresponds directly to the physical table, retrieval is faster than non-clustered table. Pros Direct / single access to the table Good for sequential retrieval Minimize page transfer and maximize cache hit Cons Modification (insertion, updates, deletes) require extra work, such as re-ordering of the tables so that entries are in order. Non-clustered index Non-clustered index does not correspond to actual orderings in the physical table. It has pointers to the actual entry in the table and is stored in a separately from the table. Pros Can have multiple non-clustered indexes Insertion into the physical table does not affect performance Cons Lookup is costly (No locality, cache misses) Slower data access compared to clustered index Need extra space to store the index References https://www.youtube.com/watch?v=HauoKagBM_c&amp;list=PLzzVuDSjP25QCp7S4_8b-rX9vytv6OqsZ&amp;index=5 https://www.guru99.com/clustered-vs-non-clustered-index.html]]></summary></entry><entry><title type="html">tcmalloc</title><link href="https://kyungyunlee.github.io/study/2020/11/30/tcmalloc.html" rel="alternate" type="text/html" title="tcmalloc"/><published>2020-11-30T00:00:00+00:00</published><updated>2020-11-30T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2020/11/30/tcmalloc</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2020/11/30/tcmalloc.html"><![CDATA[<p>tcmalloc is a thread-caching malloc developed by Google.</p> <p>It is good for handling multi-threading situations.</p> <p>The main benefit is that there is no need to use locks in case of small object allocations, since each thread has its own pre-allocated thread-local cache.</p> <p>Objects that are less than 32K are considered small.</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gl6yjth982j313y0u0ka0.jpg" alt="Screen Shot 2020-11-30 at 9.59.23 AM"/></p> <h4 id="main-components">Main Components</h4> <ul> <li> <p>Thread-local cache</p> <p>Each thread has its own pre-allocated cache. This cache is a list of singly linked lists. Each linked list consists of same sized object classes. The size-classes are separated by 8 bytes, 16 bytes, 32 bytes, and up to 256 bytes, totalling 170 classes. The smallest size class is 8 bytes, the largest is 32K.</p> <p>When the thread asks for a small object, OS will identify this thread’s cache and retrieve the free object from its cache. If the linked list for a size-class is empty, it is refilled from the central free list.</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gl6yk010flj30nm0fm757.jpg" alt="Screen Shot 2020-11-30 at 10.11.55 AM" style="zoom:50%;"/></p> </li> <li> <p>Page heap</p> <p>Page heap is the “main” memory. This is initialized first when the program starts. It is shared by all threads, which means that accessing page heap requires a lock. When central free list needs more memory, it accesses page heap.</p> <p>Memory in page heap is organized into spans. Spans are continguous pages. Its size ranges from 1 to 256 pages.</p> <p>For efficient management of spans, tcmalloc uses 2 or 3-level radix tree, which maps page number to span.</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1gl6yk60jacj30rc0hyq4g.jpg" alt="Screen Shot 2020-11-30 at 10.27.23 AM" style="zoom:50%;"/></p> </li> <li> <p>Central free list</p> <p>Central free list is shared by all threads. It manages memory in spans, like the page heap. However, each span is segmented into size-classes, so that when the thread caches need more memory, it can be easily taken from the span.</p> </li> </ul> <h4 id="functions">Functions</h4> <p><strong><code class="language-plaintext highlighter-rouge">void * tc_central_init ()</code></strong></p> <ul> <li> <p>Initialize page heap</p> </li> <li> <p>Initialize central free list</p> </li> <li> <p>Initialize radix tree</p> </li> </ul> <p><strong><code class="language-plaintext highlighter-rouge">void * tc_thread_init()</code></strong></p> <ul> <li>Find current thread id</li> <li>Find if there are enough space for building a thread cache <ul> <li>How much memory to allocate per thread cache?</li> </ul> </li> <li>Initialize thread cache</li> </ul> <p><strong><code class="language-plaintext highlighter-rouge">void * tc_malloc (size_t size)</code></strong></p> <ol> <li>Check if size is small or large</li> <li>If it is small, find current thread and perform <strong>small object allocation</strong> with its thread cache</li> <li>If it is large, perform <strong>large object allocation</strong> with page heap</li> <li>Return the beginning of memory location</li> </ol> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pthread_mutex_t</span> <span class="n">lock</span><span class="p">;</span> 

<span class="kt">void</span> <span class="o">*</span> <span class="nf">tc_malloc</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">size</span><span class="p">)</span> <span class="p">{</span>
  <span class="kt">void</span> <span class="o">*</span> <span class="n">memloc</span><span class="p">;</span> 
  <span class="c1">// Check if size is small or large </span>
  <span class="k">if</span> <span class="p">(</span><span class="n">size</span> <span class="o">&lt;=</span> <span class="n">MAX_SMALL_SIZE</span><span class="p">)</span> <span class="p">{</span> 
  	<span class="n">memloc</span> <span class="o">=</span> <span class="n">small_object_allocation</span><span class="p">(</span><span class="n">size</span><span class="p">);</span> 
  <span class="p">}</span> 
  <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// initiate lock </span>
    <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span>
    
  	<span class="n">memloc</span> <span class="o">=</span> <span class="n">large_object_allocation</span><span class="p">(</span><span class="n">size</span><span class="p">);</span>
		<span class="c1">// free lock </span>
    <span class="n">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">lock</span><span class="p">);</span> 
  <span class="p">}</span> 
  <span class="k">return</span> <span class="n">memloc</span><span class="p">;</span> 
<span class="p">}</span>
</code></pre></div></div> <p><strong><code class="language-plaintext highlighter-rouge">Object * small_object_allocation (size_t size)</code></strong></p> <ol> <li>Map size -&gt; size_class</li> <li>Get current thread id and its thread cache</li> <li>Get the freelist of the current size_class</li> <li>If the free list is not empty, return the first object</li> <li>If the free list is empty, <ol> <li><code class="language-plaintext highlighter-rouge">get_object_from_central_freelist(size_t size_class)</code></li> <li>put it into the current free list</li> <li>Return the first object</li> </ol> </li> <li>If the central free list is empty, <ol> <li><code class="language-plaintext highlighter-rouge">get_pages_from_central_heap (size_t size_class)</code></li> <li>divide it into objects of size_class</li> <li>put it inside the central free list.</li> <li><code class="language-plaintext highlighter-rouge">get_object_from_central_freelist(size_t size_class)</code></li> <li>put it into the current free list</li> <li>Return the first object</li> </ol> </li> </ol> <p><strong><code class="language-plaintext highlighter-rouge">Span * large_object_allocation(size_t size)</code></strong></p> <ol> <li> <p>Round size -&gt; page_size</p> </li> <li> <p>From page heap, get the free list (span list) for this page_size</p> </li> <li> <p>If the free list is not empty</p> <ol> <li>Return the first span</li> </ol> </li> <li> <p>If the free list is empty,</p> <ol> <li>Go to the next page size’s free list until you find a non-empty free list.</li> <li>If the last free list is empty, <ol> <li>Get memory from the system</li> </ol> </li> <li>If there are left over pages, insert the left over pages into the corresponding free list.</li> </ol> </li> </ol> <p><strong><code class="language-plaintext highlighter-rouge">void tc_free(void * ptr)</code></strong></p> <ol> <li> <p>Compute the page number from radix tree</p> </li> <li> <p>Check if the size is small or not</p> </li> <li> <p>If the object is small</p> <ol> <li> <p>Get size_class</p> </li> <li> <p>Find out current thread id and its thread cache</p> </li> <li> <p>Insert into the free list of size_class</p> </li> </ol> </li> <li> <p>If the object is large</p> <ol> <li>Check the pages that are used by this object.</li> <li>Merge with adjacent pages if they are free</li> <li>Return the merged page into the page heap</li> </ol> </li> </ol>]]></content><author><name></name></author><category term="study"/><category term="CS"/><summary type="html"><![CDATA[tcmalloc is a thread-caching malloc developed by Google.]]></summary></entry><entry><title type="html">Multithreaded programming in C</title><link href="https://kyungyunlee.github.io/study/2020/11/30/threads.html" rel="alternate" type="text/html" title="Multithreaded programming in C"/><published>2020-11-30T00:00:00+00:00</published><updated>2020-11-30T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2020/11/30/threads</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2020/11/30/threads.html"><![CDATA[<p>I am reviewing threads, as I work on my assignment, which builds multi-threaded server with I/O multiplexing.</p> <h3 id="briefly-about-threads">Briefly about threads</h3> <p>Threads are often referred to as light-weight processes, because they are literally lighter than processes. What’s lighter? The size of a thread instance (less memory) and therefore, saving creation and destruction time.</p> <p>They are often preferred over processes, when one needs to run large number of tasks and creating that many number of processes takes too much memory and time.</p> <p>There are different use cases for threads and processes, so use them appropriately by needs.</p> <p>For instance, chrome tabs are implemented as individual processes, because then if one tab is killed, the others will still remain safe.</p> <p><strong>Processes</strong></p> <ul> <li>Each process is independent (No sharing of memory between processes)</li> <li> <p>Communication between processes can be more difficult</p> </li> <li>Useful when security is an important issue to avoid sharing of memory.</li> </ul> <p><strong>Threads</strong></p> <ul> <li> <p>Threads are executed within processes (Every process has at least one thread : the main thread)</p> </li> <li>Share virtual address space, system memory along with other threads in the same process</li> <li>Has its own stack and registers</li> </ul> <h4 id="thread-related-functions-in-c">Thread-related functions in C</h4> <p><strong><code class="language-plaintext highlighter-rouge">pthread_create()</code></strong></p> <p>Obviously, we need to create a thread in order to use one. This call will create a thread from the main thread, which is a default thread that comes along with when a process starts.</p> <p><strong><code class="language-plaintext highlighter-rouge">pthread_join ()</code></strong></p> <p>Let’s say we run multiple threads and one of the threads take much much longer than the others. If we don’t call join, the main thread may exit before all the threads are done with their job. This will create zombie threads. Therefore, if it is necessary to wait for all the threads to finish their tasks, it is important to call join to guarantee that all threads are done before the program exits.</p> <p><strong><code class="language-plaintext highlighter-rouge">pthread_mutex_lock()</code></strong>, <strong><code class="language-plaintext highlighter-rouge">pthread_mutex_unlock()</code></strong></p> <p>As mentioned in the intro, threads share memory. They can read and write to the same data. If each task assigned to threads modifies shared data, this will result in unexpected error from race condition. Race condition happens when threads access and change the same data almost at the same instant, so they end up reading and modifying the wrong data. Therefore, to prevent this from happening, it is important to make reading and writing operations atomic, so that when one thread is accessing and doing whatever it wants with the data, no other threads can access that same data.</p> <p><strong><code class="language-plaintext highlighter-rouge">pthread_cond_signal()</code></strong>, <strong><code class="language-plaintext highlighter-rouge">pthread_cond_wait()</code></strong></p> <p>Condition variable is needed to improve cpu usage by keeping threads in waiting status until they receive some external signal, rather than making the thread constantly check for notification.</p> <h4 id="thread-pool">Thread pool</h4> <p>Creating thousands of threads for each job can be quite inefficient, especially in terms of memory. In this case, using thread pool would be a better choice. Thread pool makes use of limited number of threads by assigning multiple jobs to each thread. For instance, to execute 10,000 jobs, instead of creating 10,000 threads, we can create 100 threads and let each of them perform 100 jobs each.</p> <ol> <li>Create thread pool (ex. 10 threads). For each thread in the thread pool, it will constantly watch for a new task to be assigned.</li> <li>When a new task is created, put it into a queue.</li> <li>When a thread receives a new task, it will dequeue and handle the task.</li> </ol> <p>Use condition variable to improve the performance, so that each thread does not constantly check if a client arrived or not.</p> <p>Simple example of a server using thread pool.</p> <p>It recieves many client requests (100s, 1000s …) and it distributes the client requests into 10 threads.</p> <p>(This is not a full code, refer to the link in the reference section for the full code.)</p> <div class="language-c highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">#include ...
#include</span> <span class="cpf">&lt;pthread.h&gt;</span><span class="cp">
#include ...
</span>
<span class="cp">#define SERVERPORT 22000
#define THREAD_POOL_SIZE 10 
</span>
<span class="k">typedef</span> <span class="k">struct</span> <span class="n">sockaddr_in</span> <span class="n">SA_IN</span><span class="p">;</span>
<span class="k">typedef</span> <span class="k">struct</span> <span class="n">sockaddr</span> <span class="n">SA</span><span class="p">;</span>

<span class="n">pthread_t</span> <span class="n">thread_pool</span><span class="p">[</span><span class="n">THREAD_POOL_SIZE</span><span class="p">];</span>
<span class="n">pthread_mutex_t</span> <span class="n">mutex</span> <span class="o">=</span> <span class="n">PTHREAD_MUTEX_INITIALIZER</span><span class="p">;</span>
<span class="n">pthread_cond_t</span> <span class="n">cond_var</span> <span class="o">=</span> <span class="n">PTHREAD_COND_INITIALIZER</span><span class="p">;</span>

<span class="kt">void</span> <span class="o">*</span> <span class="nf">thread_func</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span> <span class="n">arg</span><span class="p">);</span>
<span class="kt">void</span> <span class="o">*</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span> <span class="n">pclient</span><span class="p">);</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(){</span>
  <span class="c1">// Create threads </span>
  <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span><span class="o">=</span><span class="mi">0</span><span class="p">;</span> <span class="o">&lt;</span><span class="n">THREAD_POOL_SIZE</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">){</span>
    <span class="n">pthread_create</span><span class="p">(</span><span class="o">&amp;</span><span class="n">thread_pool</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="nb">NULL</span><span class="p">,</span> <span class="n">thread_func</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>
  <span class="p">}</span>
  
  <span class="c1">// Call socket(), bind(), listen() to open up the server socket </span>
  <span class="n">server_socket</span> <span class="o">=</span> <span class="n">Open_listenfd</span><span class="p">(</span><span class="n">SERVERPORT</span><span class="p">);</span>
  
  <span class="c1">// Don't end the connection until the server explicitly gets turned off.</span>
  <span class="k">while</span><span class="p">(</span><span class="mi">1</span><span class="p">){</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Waiting for connections...</span><span class="se">\n</span><span class="s">"</span><span class="p">);</span>
    <span class="n">addr_size</span> <span class="o">=</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">SA_IN</span><span class="p">);</span>
    
    <span class="c1">// When a client sends connect request, accept it </span>
    <span class="n">client_socket</span> <span class="o">=</span> <span class="n">Accept</span> <span class="p">(</span><span class="n">server_socket</span><span class="p">,</span> <span class="p">(</span><span class="n">SA</span><span class="o">*</span><span class="p">)</span> <span class="o">&amp;</span><span class="n">client_addr</span><span class="p">,</span> <span class="p">(</span><span class="n">socklen_t</span> <span class="o">*</span><span class="p">)</span><span class="o">&amp;</span><span class="n">addr_size</span><span class="p">);</span>
    
    <span class="cm">/** THREAD POOL PART **/</span>
    <span class="c1">// Insert the new incoming client into the queue </span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">pclient</span> <span class="o">=</span> <span class="n">malloc</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span> <span class="c1">// Using int pointer to meet the pthread_create function form.</span>
    <span class="o">*</span><span class="n">pclient</span> <span class="o">=</span> <span class="n">client_socket</span><span class="p">;</span> 
    <span class="c1">// Call lock when inserting the new client into the queue. </span>
    <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
    <span class="n">enqueue</span><span class="p">(</span><span class="n">pclient</span><span class="p">);</span>
    <span class="c1">// Signal the thread that a new client came. </span>
    <span class="n">pthread_cond_signal</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cond_var</span><span class="p">);</span>
    <span class="n">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
  <span class="p">}</span>
	<span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span> <span class="nf">thread_func</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span> <span class="n">arg</span><span class="p">){</span>
  <span class="cm">/* This function is run in each thread */</span>
  
  <span class="c1">// Just continuously run without returning </span>
  <span class="k">while</span> <span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="o">*</span> <span class="n">pclient</span><span class="p">;</span>
    <span class="n">pthread_mutex_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
    <span class="c1">// Without condvar, this part will not exist, and the thread will constantly check if there is a client in the queue.</span>
    <span class="k">if</span> <span class="p">((</span><span class="n">pclient</span> <span class="o">=</span> <span class="n">dequeue</span><span class="p">())</span> <span class="o">==</span> <span class="nb">NULL</span><span class="p">){</span>
      <span class="c1">// If there is no client, wait until a signal arrives as a new client arrives.</span>
      <span class="n">pthread_cond_wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cond_var</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
      <span class="n">pclient</span> <span class="o">=</span> <span class="n">dequeue</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="n">pthread_mutex_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">mutex</span><span class="p">);</span>
    
    <span class="c1">// If there is a client to handle, handle the client </span>
    <span class="k">if</span> <span class="p">(</span><span class="n">pclient</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">){</span>
      <span class="n">handle_connection</span><span class="p">(</span><span class="n">pclient</span><span class="p">);</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kt">void</span> <span class="o">*</span> <span class="nf">handle_connection</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span> <span class="n">pclient</span><span class="p">){</span>
  <span class="cm">/* Read client's message from client socket, 
  do whatever server needs to do to process the request  from the client, 
  return the result back to the client,
  and close the current socket. 
  */</span>
<span class="p">}</span>
</code></pre></div></div> <h4 id="parallelism-vs-concurrency">Parallelism vs concurrency</h4> <p><strong>Parallelism</strong> : Executing multiple tasks at the same time.</p> <p>Ex) Multi-processing in multi-core machine</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1glok8asc1bj30en08vglk.jpg" alt="Screen Shot 2020-12-15 at 4.12.38 PM" style="zoom: 67%;"/></p> <p><strong>Concurrency</strong> : Only one task can be executed at a time, but cpu utilization is maximized by selecting and running multiple tasks.</p> <p>Ex) Mult-tasking in single-core machine through time slicing.</p> <p><img src="https://tva1.sinaimg.cn/large/0081Kckwgy1glousnk0z6j30h408q74a.jpg" alt="Screen Shot 2020-12-15 at 4.12.43 PM" style="zoom:67%;"/></p> <h4 id="reference">Reference</h4> <ul> <li>[Programming with Threads by Jacob Sorber](https://www.youtube.com/playlist?list=PL9IEJIKnBJjFZxuqyJ9JqVYmuFZHr7CFM)</li> </ul>]]></content><author><name></name></author><category term="study"/><category term="CS"/><summary type="html"><![CDATA[I am reviewing threads, as I work on my assignment, which builds multi-threaded server with I/O multiplexing.]]></summary></entry><entry><title type="html">SVM</title><link href="https://kyungyunlee.github.io/study/2020/07/23/svm.html" rel="alternate" type="text/html" title="SVM"/><published>2020-07-23T00:00:00+00:00</published><updated>2020-07-23T00:00:00+00:00</updated><id>https://kyungyunlee.github.io/study/2020/07/23/svm</id><content type="html" xml:base="https://kyungyunlee.github.io/study/2020/07/23/svm.html"><![CDATA[<p>Notes from <a href="https://youtu.be/_PwhiWxHK8o">professor Patrick Winston’s SVM lecture</a></p> <p>SVM is a supervised classification method.</p> <p><strong>All about decision boundaries</strong></p> <p>Other methods of drawing decision boundaries</p> <ul> <li> <p>Nearest neighbour</p> </li> <li> <p>ID trees</p> </li> <li> <p>Neural nets</p> </li> </ul> <p><strong>SVM takes on the “widest street approach” using the support vectors only</strong></p> <h4 id="decision-rule">Decision rule</h4> <p>[image goes here]</p> <p>Let $\bar{w}$ be a vector perpendicular to the decision boundary we set.</p> <p>Our mission is to classify an arbitrary vector $\bar{u}$.</p> <p>In order to figure this out, we need a decision rule; some kind of criteria that can tells us if the vector is positive or negative.</p> <p>An option is by projecting $\bar{u}$ onto $\bar{w}$ through dot product and see if the resulting value plus some constant $b$ is greater than 0. If it is, we say it is a positive sample given our decision boundary. \(\bar{w} \cdot \bar{u} + b \geq 0 \tag{1}\) That seems easy. But the problem is how to determine $\bar{w}$ and constant $b$.</p> <p>There are infinitely many options for $\bar{w}$ , since there are infinitely many perpendicular lines to the boundary (A vector of any length as long as it is perpendicular).</p> <p>So we don’t have enough constraints to choose one $\bar{w}$ and $b$.</p> <h4 id="constraints">Constraints</h4> <p>To narrow down our options, let’s add more constraints. \(\overrightarrow{w} \cdot \overrightarrow{x}_{+} + b \geq 1\)</p> \[\overrightarrow{w} \cdot \overrightarrow{x}_{-} + b \leq -1\] <p>This says that a positive sample must be “really positive” and a negative sample must be “really negative”. We want our decision boundary to ensure that there is enough safety margin for separating positive and negative samples.</p> <p>But we have two equations here. How can we make it into one for mathematical convienience?</p> <p>Let $y_i = 1$ for positive samples and $y_i = -1$ for negative samples.</p> <p>We can multiply both sides of the equation by $y$. \(y_i(\overrightarrow{w} \cdot \overrightarrow{x}_{+i} + b) \geq 1\)</p> \[y_i(\overrightarrow{w} \cdot \overrightarrow{x}_{-i} + b) \geq 1\] <p>Note that multiplying $y = -1$ on both sides in the negative sample case flips the direction of the equality symbol, so we have the same looking equation! \(y_i(\overrightarrow{w} \cdot \overrightarrow{x}_i + b) \geq 1\) Organize a little bit and we get, \(y_i(\overrightarrow{w} \cdot \overrightarrow{x}_i + b) - 1 \geq 0\) In addition, we say that the samples that are on the gutter (located exactly on the width of the street) meet the following equation. \(y_i(\overrightarrow{w} \cdot \overrightarrow{x}_i + b) - 1 = 0 \tag{2}\) This will be the constraint that we will stick to.</p> <p>By the way, the samples that are on the gutter are called “support vectors”. These samples are the main focus for SVM.</p> <h4 id="width-of-the-boundary">Width of the boundary</h4> <p>Remember, our main goal is to find the widest street that can separate the positive to negative samples.</p> <p>[drawing]</p> <p>But we need to find out how to compute the width of the street.</p> <p>The width of the street can be expressed as a dot product between the unit vector that is perpendicular to our decision boundary and the distance between the positive and the negative sample on the gutter. \(width = (\overrightarrow{x}_+ - \overrightarrow{x}_-) \cdot \frac{\overrightarrow{w}}{\lVert{\overrightarrow{w}}\rVert}\) From constraint (2), \(\overrightarrow{w} \cdot \overrightarrow{x}_+ = 1 - b\)</p> \[\overrightarrow{w} \cdot \overrightarrow{x}_- = 1 + b\] <p>Then, the width simplifies to \(width = (1-b -1 +b) \cdot \frac{\overrightarrow{w}}{\lVert{\overrightarrow{w}}\rVert} = \frac{2}{\lVert{\overrightarrow{w}}\rVert}\)</p> <p>Our goal is to maximize the width. So, the objective function is simply \(max \frac{1}{\lVert{\overrightarrow{w}}\rVert}\) Or, \(min \lVert{\overrightarrow{w}}\rVert\) Or, even more mathematically convieniently, \(min \frac{1}{2}\lVert{\overrightarrow{w}}\rVert ^2 \tag{3}\)</p> <h4 id="using-lagrange-multiplier">Using lagrange multiplier</h4> <p>So we have an objective function (3) and an equality constraint function (2). This can be formulated as an optimization problem. \(min \quad \frac{1}{2}\lVert{\overrightarrow{w}}\rVert ^2 \\ s.t \quad y_i(\overrightarrow{w} \cdot \overrightarrow{x}_i + b) - 1 = 0 \quad \forall i\) With lagrange multiplier theorem for equality constrained optimization, we can combine these two functions into one. \(L = \frac{1}{2}\lVert{\overrightarrow{w}}\rVert ^2 - \Sigma \alpha_i[y_i(\overrightarrow{w} \cdot \overrightarrow{x}_i + b) - 1] \tag{4}\) where $\alpha_i$ are lagrange multipliers for each sample.</p> <p>$\alpha_i$ ‘s are equal to zero for all samples that are not on the gutter.</p> <p>To find the extremum (minimum or maximum) of $L$, we find the derivative and set it to 0. \(\frac{\delta L}{\delta \overrightarrow{w}} = \overrightarrow{w} - \Sigma \alpha_i y_i \overrightarrow{x}_i = 0\)</p> \[\overrightarrow{w} = \Sigma \alpha_i y_i \overrightarrow{x}_i \tag{5}\] <p>We can see that $\bar{w}$ that we wanted to find is now a linear sum of samples!</p> <p>How about differentiating w.r.t to $b$? \(\frac{\delta L}{\delta b} = - \Sigma \alpha_i y_i = 0 \tag{6}\) We have now obtained 2 more valuable functions (eq 5, 6).</p> <p>We will substitute these into eq (4). \(L = \frac{1}{2}(\Sigma \alpha_i y_i \overrightarrow{x_i})(\Sigma \alpha_j y_j \overrightarrow{x_j}) - (\Sigma \alpha_i y_i \overrightarrow{x_i})(\Sigma \alpha_j y_j \overrightarrow{x_j}) - \Sigma \alpha_i y_i b + \Sigma \alpha_i\) Since $\Sigma \alpha_i y_i b = b \Sigma \alpha_i y_i = 0 $ from eq (6), \(L = \Sigma \alpha_i - \frac{1}{2}\Sigma \Sigma \alpha_i \alpha_j y_i y_j x_i \cdot x_j \tag{7}\) Why did we get so far as this?</p> <p>If we find $\alpha_i$, then we can now compute $\overrightarrow{w}$ and $b$ from eq (5) and eq (2) and our samples.</p> <p>We ultimately found out our objective function is associated in terms of the samples we’ve got. Eq (7), we see that it depends on the dot product of samples in our data.</p> <p>In addition, our decision rule in eq (1) becomes \(\Sigma \alpha_i y_i \overrightarrow{x}_i \cdot \overrightarrow{u} + b \geq 0 \quad then \quad '+'\) and therefore, it is also dependent on the dot product of our samples and an unknown vector.</p> <p>So all of our equations we are interested are dependent on the dot product with our samples.</p> <p>Since $L$ is a quadratic programming problem, finding $\alpha$ will not get stuck in local maximum, unlike neural nets.</p> <h4 id="kernel-function">Kernel function</h4> <p>However, SVM doesn’t work well for samples that are not linearly separable.</p> <p>But that’s ok. If samples are not linearly separable, we will then apply some transformation, $\phi(*)$, on our samples to map them into another space, where they become linearly separable and then apply SVM.</p> <p>Since all we need is the dot product between samples, we actually don’t need to figure out $\phi(*)$ itself, but rather the result of the dot product of the transformation. \(K(x_i, x_j) = \phi(x_i) \cdot \phi(x_j)\) So our mission, in case of non linearly separable case, will be to find the kernel function, $K$.</p> <p>Some examples of common kernel functions are \((u_i \cdot u_j + 1)^n\)</p> \[e ^{-\frac{\lVert u_i - u_j \rVert}{\sigma}}\] <h4 id="summary">Summary</h4> <p>The goal of SVM is to determine the widest street (boundary) using samples that lie on the gutter, called support vectors. SVM is always able to find the solution to the linear classification problem with the given samples.</p> <p>Tools we have used for computing decision boundary ($\overrightarrow{w}$ and $b$) in SVM</p> <ol> <li>Decision rule</li> <li>Constraints</li> <li>“Maximizing the width” of the street</li> </ol> <h4 id="future-notes">Future notes</h4> <ul> <li>https://www.youtube.com/watch?v=eHsErlPJWUU&amp;hd=1</li> <li>A bit more on kernel functions and its uses in other methods</li> </ul>]]></content><author><name></name></author><category term="study"/><category term="ML"/><summary type="html"><![CDATA[Notes from professor Patrick Winston’s SVM lecture]]></summary></entry></feed>