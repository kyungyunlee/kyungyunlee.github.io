<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Energy-based models and Score matching models | Kyung Yun Lee</title> <meta name="author" content="Kyung Yun Lee"> <meta name="description" content="Diffusion Models Study"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%B6&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://kyungyunlee.github.io/blog/2025/EBM-Score/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Kyung Yun </span>Lee</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Energy-based models and Score matching models</h1> <p class="post-meta">November 29, 2025</p> <p class="post-tags"> <a href="/blog/2025"> <i class="fas fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/statistics"> <i class="fas fa-hashtag fa-sm"></i> statistics,</a>   <a href="/blog/tag/diffusion"> <i class="fas fa-hashtag fa-sm"></i> diffusion</a>     ·   <a href="/blog/category/statistics"> <i class="fas fa-tag fa-sm"></i> statistics</a>   </p> </header> <article class="post-content"> <p>Energy-based models represent the pdf with an energy function, \(E_\phi(x)\). Basically, the ideally learned EBMs will tell us that higher probability data have lower energy.</p> \[p_\phi(x) = \frac{e^{-E_\phi(x)}}{Z_\phi}, Z_\phi = \int e^{-E_\phi(x)} dx\] <p>As usual, we would like to use the maximum likelihood to train EBMs:</p> \[L_{\text{MLE}}(\phi) = \mathbb{E}_{x \sim p_{\text{data}}(x)}[\text{log} p_\phi(x)] = - \mathbb{E}_{x \sim p_{\text{data}}(x)}[E_\phi(x)] - \text{log} Z_\phi\] <p>The first term tells us that the goal is to minimize the expected energy of observed data, i.e. maximize their probability. The second term is a regularizer that related to the entropy.</p> <p>Entropy of the model is: \(H(p_\phi) = -\mathbb{E}_{x \sim p_\phi}[\text{log} p_\phi(x)] = \mathbb{E}_{x \sim p_\phi}[E_\phi(x)] + \text{log} Z_\phi.\)</p> <p>As \(Z_\phi\) is a normalizing constant, if it increases, it means that the probability will generally decrease, i.e. more evenly distributed across space. This means that the overall entropy increases. This brings an effect of improved mode coverage.</p> <h3 id="challenge-in-ebms">Challenge in EBMs</h3> <p>Directly optimizing MLE in this way is a challenge, as \(Z_\phi\) is intractable. We can get away from this by playing in the gradient space as by taking the gradient of the log probability, the normalizing constant disappears. So now, comes the score function.</p> <p>Score function is a general term that refers to the gradient of the log probability. It tells us the direction of higher probability. It describes the vector field.</p> \[s(x) = \nabla_x \text{log} p(x)\] <p>If we plug in the energy function here, we get the following without the normalizing constant.</p> \[s_\phi(x) = \nabla_x \text{log} p_\phi(x) = - \nabla_x E_\phi(x)\] <p>So, instead of training EBMs to maximize the likelihood, we can train it by matching the model score to the true score function, \(s(x)\).</p> \[L_{SM}(\phi) = \frac{1}{2}\mathbb{E}_{x\sim p_\text{data}}|| s_\phi(x) - s(x) ||_2^2 \\ = \frac{1}{2}\mathbb{E}_{x\sim p_\text{data}}|| \nabla_x \text{log} p_\phi(x) - \nabla_x \text{log} p_{\text{data}}(x)||_2^2\] <p>As the true score function is not possible to compute, Hyvarinen et al. have shown that there is an equivalent form so that the objective only depends on \(s_\phi\).</p> \[L_{SM}(\phi) = \mathbb{E}_{x\sim p_\text{data}}[ \text{Tr}(\nabla_x s_\phi(x)) + \frac{1}{2} || s_\phi(x) ||_2^2]\] <p>Minimizing the second term simply tells us that the score should be small for highly probable data (high probability region should have 0 gradient (maximum)). Thus it is at best 0. This leads to the goal of making first term negative. It is the divergence term as it is the trace of the second derivative. Negative divergence means that around the high probability points, the vector field should point inwards, i.e. is a sink.</p> <h3 id="from-energy-based-models-to-score-based-models">From energy-based models to score-based models</h3> <p>Jacobian is expensive to compute. So came the idea that instead of bothering about energies to just directly work with scores. Can’t we just train a neural network that predicts score functions instead of energy functions?</p> <p>Yes, but the problem remains that the true score function is intractable. The idea to overcome this is by injecting known amount of noise to data and working with the “noisy” data distribution and conditionals.</p> \[\tilde{x} = x + N(0, \sigma^2I)\] \[p_\sigma(\tilde{x}) = \int p_\sigma(\tilde{x}|x) p_{\text{data}}(x)dx\] \[L_{SM}(\phi) = \frac{1}{2}\mathbb{E}_{\tilde{x} \sim p_\sigma}[|| s_\phi(\tilde{x}) - \nabla_{\tilde{x}} \text{log} p_\sigma(\tilde{x})||_2^2]\] <p>Using the conditioning technique, we can avoid the gradient of the marginal and just work with the conditional. The difference is only a constant, thus optimizing the conditional is equivalent to optimizing with the marginal distribution.</p> \[L_{DSM}(\phi) = \frac{1}{2}\mathbb{E}_{\tilde{x} \sim p_\sigma(\cdot | x), x \sim p_\text{data}}[|| s_\phi(\tilde{x}) - \nabla_{\tilde{x}} \text{log} p_\sigma(\tilde{x}|x)||_2^2]\] <p>The conditional is very easy to compute as we have designed the noisy version ourselves. For instance, for a Gaussian noise: \(p_\sigma(\tilde{x} \vert x) = N(\tilde{x}; x, \sigma^2I)\). The conditional score is then \(\nabla_{\tilde{x}} \text{log} p_\sigma(\tilde{x}\vert x) = -\frac{\tilde{x} - x}{\sigma^2}\).</p> <p>Thus, the objective simplifies in this case to:</p> \[L_{DSM}(\phi) = \frac{1}{2}\mathbb{E}_{\tilde{x} \sim p_\sigma(\cdot | x), x \sim p_\text{data}}[|| s_\phi(\tilde{x}) + \frac{\tilde{x} - x}{\sigma^2} ||_2^2].\] <p><strong>References</strong></p> <ul> <li>Lai, Chieh-Hsin, et al. “The principles of diffusion models.” arXiv preprint arXiv:2510.21890 (2025).</li> </ul> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Kyung Yun Lee. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>